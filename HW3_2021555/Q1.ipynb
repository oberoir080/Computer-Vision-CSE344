{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.51.2)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: open_clip_torch in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.32.0)\n",
      "Requirement already satisfied: torch>=1.9.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from open_clip_torch) (2.2.1+cu121)\n",
      "Requirement already satisfied: torchvision in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from open_clip_torch) (0.17.1+cu121)\n",
      "Requirement already satisfied: regex in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from open_clip_torch) (2024.11.6)\n",
      "Requirement already satisfied: ftfy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from open_clip_torch) (6.3.1)\n",
      "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from open_clip_torch) (4.67.1)\n",
      "Requirement already satisfied: huggingface-hub in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from open_clip_torch) (0.30.2)\n",
      "Requirement already satisfied: safetensors in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from open_clip_torch) (0.5.3)\n",
      "Requirement already satisfied: timm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from open_clip_torch) (1.0.15)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9.0->open_clip_torch) (12.8.93)\n",
      "Requirement already satisfied: wcwidth in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ftfy->open_clip_torch) (0.2.13)\n",
      "Requirement already satisfied: packaging>=20.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub->open_clip_torch) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub->open_clip_torch) (6.0.2)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub->open_clip_torch) (2.32.3)\n",
      "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchvision->open_clip_torch) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchvision->open_clip_torch) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch>=1.9.0->open_clip_torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip_torch) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip_torch) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip_torch) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip_torch) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch>=1.9.0->open_clip_torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install open_clip_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from open_clip import create_model_from_pretrained, get_tokenizer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "texts = [\"man holding a dog\", \n",
    "    \"man holding a black coloured dog\", \n",
    "    \"a man wearing a white shirt and gray pants\",\n",
    "    \"a man wearing a white shirt and gray pants and holding a dog\",\n",
    "    \"man wearing a white shirt\", \n",
    "    \"a bookshelf in the background\", \n",
    "    \"a running dog\", \"a running man\", \n",
    "    \"a man with a dog face\", \n",
    "    \"a dog with a man face\" ]\n",
    "\n",
    "clip = \"openai/clip-vit-base-patch32\"\n",
    "image = Image.open(\"sample_image.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_text_scorer(model_name, texts, image, device):\n",
    "    model = CLIPModel.from_pretrained(model_name).to(device)\n",
    "    processor = CLIPProcessor.from_pretrained(model_name)\n",
    "\n",
    "    inputs = processor(text=texts, images=image, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    logits_per_image = outputs.logits_per_image\n",
    "    scores = logits_per_image.squeeze().cpu().tolist()\n",
    "\n",
    "    return scores\n",
    "\n",
    "def clips_text_scorer(model_name, texts, image, device):\n",
    "    model, preprocess = create_model_from_pretrained(model_name)\n",
    "    tokenizer = get_tokenizer(model_name)\n",
    "\n",
    "    image_tensor = preprocess(image).unsqueeze(0).to(device)\n",
    "\n",
    "    text = tokenizer(texts, context_length = model.context_length).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image_tensor)\n",
    "        text_features = model.encode_text(text)\n",
    "\n",
    "        image_features_norm = F.normalize(image_features, dim=-1)\n",
    "        text_features_norm = F.normalize(text_features, dim=-1)\n",
    "\n",
    "        cosine_similarity = image_features_norm @ text_features_norm.T\n",
    "\n",
    "        logit_scale = model.logit_scale.exp()\n",
    "        scaled_similarity = cosine_similarity * logit_scale\n",
    "\n",
    "        scores = scaled_similarity.squeeze().cpu().tolist()\n",
    "\n",
    "        return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = clip_text_scorer(clip, texts, image, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man holding a dog | Similarity Score: 30.558883666992188\n",
      "man holding a black coloured dog | Similarity Score: 29.479265213012695\n",
      "a man wearing a white shirt and gray pants | Similarity Score: 24.179716110229492\n",
      "a man wearing a white shirt and gray pants and holding a dog | Similarity Score: 32.02540588378906\n",
      "man wearing a white shirt | Similarity Score: 23.536558151245117\n",
      "a bookshelf in the background | Similarity Score: 23.917461395263672\n",
      "a running dog | Similarity Score: 23.639495849609375\n",
      "a running man | Similarity Score: 22.64459228515625\n",
      "a man with a dog face | Similarity Score: 25.942140579223633\n",
      "a dog with a man face | Similarity Score: 25.717147827148438\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f\"{texts[i]} | Similarity Score: {scores[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips = \"hf-hub:UCSC-VLAA/ViT-L-14-CLIPS-224-Recap-DataComp-1B\"\n",
    "\n",
    "clips_scores = clips_text_scorer(clips, texts, image, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man holding a dog | Similarity Score: 24.29550552368164\n",
      "man holding a black coloured dog | Similarity Score: 23.524459838867188\n",
      "a man wearing a white shirt and gray pants | Similarity Score: 4.223145008087158\n",
      "a man wearing a white shirt and gray pants and holding a dog | Similarity Score: 24.82670021057129\n",
      "man wearing a white shirt | Similarity Score: 11.843993186950684\n",
      "a bookshelf in the background | Similarity Score: 17.921937942504883\n",
      "a running dog | Similarity Score: 13.983269691467285\n",
      "a running man | Similarity Score: 5.167665958404541\n",
      "a man with a dog face | Similarity Score: 22.434938430786133\n",
      "a dog with a man face | Similarity Score: 21.930673599243164\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f\"{texts[i]} | Similarity Score: {clips_scores[i]}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
